{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Simple Feed-Forward Neural Network\n",
    "### Q4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=tform, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, transform=tform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NeuralNet:\n",
    "    d: int # num inputs\n",
    "    d1: int # num neurons in hidden layer\n",
    "    k: int # num classes\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.W1 = np.random.randn(self.d1, self.d) * 0.01\n",
    "        self.W2 = np.random.randn(self.k, self.d1) * 0.01\n",
    "\n",
    "    def sigmoid_fn(self, X: np.array) -> np.array:\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def softmax_fn(self, X: np.array) -> np.array:\n",
    "        # X is (k, 1)\n",
    "        softmax = np.exp(X) / np.sum(np.exp(X))\n",
    "        return softmax # (k, 1)\n",
    "\n",
    "    def forward_pass(self, X: np.array) -> np.array:\n",
    "        self.A = self.sigmoid_fn(self.W1 @ X)\n",
    "        self.Z = self.softmax_fn(self.W2 @ self.A)\n",
    "        return self.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNet(28**2, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.01\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "#trainset.data = trainset.data[:30000]\n",
    "data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 finished.\n",
      "Epoch #1 finished.\n",
      "Epoch #2 finished.\n",
      "Epoch #3 finished.\n",
      "Epoch #4 finished.\n",
      "Epoch #5 finished.\n",
      "Epoch #6 finished.\n",
      "Epoch #7 finished.\n",
      "Epoch #8 finished.\n",
      "Epoch #9 finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for b_i, (images, labels) in enumerate(data_loader):\n",
    "        W1_grad = np.zeros(nnet.W1.shape)\n",
    "        W2_grad = np.zeros(nnet.W2.shape)\n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            label = labels[i]\n",
    "\n",
    "            X = np.array(image.reshape(784, 1))\n",
    "            Y = np.zeros((10,1))\n",
    "            Y[label] = 1\n",
    "            Yp = nnet.forward_pass(X)\n",
    "\n",
    "            delZ = Yp - Y  # (10, 1)\n",
    "            delA = nnet.W2.T @ delZ  # (300, 1)\n",
    "            delSig = nnet.A * (1 - nnet.A)  # (300, 1)\n",
    "            delW1 = (delA * delSig) @ X.T\n",
    "            W1_grad += delW1\n",
    "            W2_grad += delZ @ nnet.A.T\n",
    "        W1_grad = (learn_rate / batch_size) * W1_grad\n",
    "        W2_grad = (learn_rate / batch_size) * W2_grad\n",
    "        nnet.W1 -= W1_grad\n",
    "        nnet.W2 -= W2_grad\n",
    "    print('Epoch #' + str(epoch) + ' finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for b_i, (images, labels) in enumerate(test_loader):\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        X = np.array(image.reshape(784, 1))\n",
    "        Yp = nnet.forward_pass(X)\n",
    "        yp = np.argmax(Yp)\n",
    "        if int(label) == int(yp):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9539\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / (correct + incorrect)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
